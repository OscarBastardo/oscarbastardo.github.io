<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>2021-09-26s on Oscar Bastardo</title>
    <link>https://oscarbastardo.com/2021-09-26/</link>
    <description>Recent content in 2021-09-26s on Oscar Bastardo</description>
    <generator>Hugo -- gohugo.io</generator>
    <lastBuildDate>Mon, 06 Sep 2021 00:00:00 +0000</lastBuildDate><atom:link href="https://oscarbastardo.com/2021-09-26/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Markov Decision Process</title>
      <link>https://oscarbastardo.com/2021-09-26/mdp/</link>
      <pubDate>Mon, 06 Sep 2021 00:00:00 +0000</pubDate>
      
      <guid>https://oscarbastardo.com/2021-09-26/mdp/</guid>
      <description>Markov Decision Process Introduction One of the most fundamental problems in reinforcement learning is the representation of the environment, which comprises everything that exists outside the agent. The agent interacts with the environment through actions, and the environment in turn responds to the agent with rewards and with new new situations, as shown in Figure 1.
 Figure 1: The agent-environment interaction in a MDP. Source: Sutton &amp;amp; Barto (2018).</description>
    </item>
    
  </channel>
</rss>
